# -*- coding: utf-8 -*-
"""Predictive_analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VXtCr0p_yoCYAHKIsQ37jzovHldnzZPR

#**Predictive Analytics**

Nama: Joko prabowo <br>
ID: jprabowo <br>
Email: jokoprabowo4550@gmail.com <br>

##**Data loading**
---
Proses dalam menyimpan dan memuat data untuk diproses lebih lanjut
"""

import pandas as pd

url = 'https://github.com/jokoprabowo/predictive_analytics_for_water_quallity_prediction/releases/download/dataset/diabetes.csv'
df = pd.read_csv(url)
df

"""##**Exploratory data analysis**
---
 Proses untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data.

###Deskripsi variabel
---
Proses untuk mendeskripsikan setiap variabel agar variabel tersebut dapat dimengerti secara umum

Berdasarkan informasi dari kaggle, variable-variable diatas dapat diartikan:

Variabel|Keterangan
---|---
Pregnancies|Jumlah kehamilan
Glucose|Kadar glukosa dalam darah
BloodPressure|Tekanan darah
SkinThickness|Ketebalan kulit
Insulin|Kadar insulin dalam tubuh
BMI|Index massa tubuh
DiabetesPedigreeFunction|Presentase diabetes
Age|Umur
Outcome|Nilai akhir (positif = 1) dan (negatif = 0)
"""

df.info()

"""Dari hasil diatas dapat dilihat bahwa:
*   Terdapat 6 data numerik dengan tipe data int64, yaitu: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, dan Age
*   Terdapat 2 data numerik dengan tipe data float64, yaitu: BMI, dan DiabetesPedigreeFunction
*   Terdapat 1 data kategorik dengan tipe data int64, yaitu: Outcome yang merupakan target fitur dari proyek ini.


"""

df.describe()

"""Data diatas memperlihatkan informasi statistik pada setiap kolom yaitu:

Variabel|Keterangan
---|---
count|jumlah sampel
mean|nilai rata-rata
std|standar deviasi
min|nilai minimum
25%|kuartil pertama
50%|kuartil kedua
75%|kuartil ketiga
max|nilai maximum

###Menangani missing value dan outliners
---
Proses untuk menghapus kolom yang bernilai kosong (NaN) serta terduplikat, untuk mengatasi data ganda dan data yang tidak lengkap
"""

# menampilkan total data kosong
df.isna().sum()

"""Berdasarkan hasil diatas, tidak ada data kosong dalam dataset ini

Kemudian lakukan cek terhadap data terduplikasi
"""

df.duplicated().sum()

"""Keterangan diatas menyatakan bahwa tidak ada data yang terduplikasi"""

df_features = df.columns.tolist()
df_features.remove('Outcome')

import matplotlib.pyplot as plt
import seaborn as sns

for column in df_features:
  plt.figure(figsize=(8,2))
  sns.boxplot(x=df[column])
  plt.title(f'Boxplot of {column}')
  plt.show()

"""Gambar diatas merupakan visualisasi data untuk mendeteksi outliners pada setiap fitur numerik, kemudian outliners tersebut akan diatasi menggunakan metode IQR"""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]
df.shape, df_out.shape

"""Hasil diatas merupakan total data sebelum dan sesudah menangani data outliner

###Unvariate analysis
---
Proses untuk menganalisis data terhadap satu variabel secara mandiri
"""

df_out.info()

"""Bagi fitur menjadi numerical dan categorical features berdasarkan data diatas, dan lakukan proses analisis pada setiap fiturnya"""

numerical_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
categorical_features = ['Outcome']

# Fitur outcome
feature = categorical_features[0]
count = df_out[feature].value_counts()
percent = 100*df_out[feature].value_counts(normalize=True)
df_outcome = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_outcome)
count.plot(kind='bar', title='Plot penderita diabetes');

"""Berdasarkan gambar diatas, dapat disimpulkan bahwa mayoritas responden bukan merupakan penderita diabetes (Outcome = 0)"""

df_out.hist(bins=50, figsize=(20,15))
plt.show()

"""Berdasarkan histogram diatas dapat disimpulkan bahwa:
*   Plot histogram SkinThickness dan Insulin tidak berdistribusi normal
*   Plot histogram dari Glucose, BloodPressure, dan BMI cukup berdistribusi normal
*   Plot histogram dari Pregnancies, DiabetesPedigreeFunction, dan Age berdistribusi cenderung miring ke kanan sehingga mayoritas data memiliki nilai dibawah rata-rata

###Multivariate analysis
---
Proses yang digunakan untuk menganalisis hubungan antara dua variabel atau lebih

Untuk menganalisis hubungan antara fitur target (Outcome) dengan fitur lainnya pada proyek ini, fungsi stripplot() akan digunakan sebagai visualisasi hubungannya
"""

df_features = df_out.columns.tolist()
df_features.remove('Outcome')

# Membuat plot strip perbandingan untuk setiap fitur
for column in df_features:
  plt.figure(figsize = (8, 6))
  sns.stripplot(data = df_out, x = "Outcome", y = column)
  plt.title(f'Plot strip Potability terhadap {column}')
  plt.xlabel('Potability')
  plt.ylabel(f'{column}')
  plt.show()

"""Berdasarkan visualisasi dari gambar-gambar diatas dapat disimpulkan bahwa:
*   Tidak terdapat perbedaan yang mencolok antara fitur-fitur diatas dengan kemungkinan menderita diabetes
*   Namun, dalam rentang kandungan glukosa di dalam tubuh orang pengidap diabetes berkisar 80 - 200 mg/dL namun berkisar 40 - 180 mg/dL untuk yang bukan pengidap diabetes




"""

plt.figure(figsize=(10, 8))
correlation_matrix = df_out[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Dari heatmap diatas dapat terlihat bahwa:
*   Umur punya korelasi yang cukup tinggi terhadap jumlah kehamilan, layaknya kadar insulin dalam tubuh terhadap ketebalan kulit
*   Namun Umur punya korelasi yang sangat rendah terhadap kadar insulin dalam tubuh, layaknya jumlah kehamilan terhadap ketebalan kulit

##**Data preparation**
---
Proses untuk menyiapkan data mentah agar dapat diproses dan dianalisis lebih lanjut.

###Train-Test-Split
---
Proses ini dilakukan untuk membagi data menjadi data latih(train), dan data uji(test) yang digunakan untuk membuat model

Sebelum membuat data training dan test, data perlu dipisahkan antara fitur komposisi dan fitur target
"""

from sklearn.model_selection import train_test_split

X = df_out[df_features]
y = df_out['Outcome']

# Komposisi data train dan data test adalah 80% dan 20%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

print("Ukuran X_train: ", X_train.shape)
print("Ukuran X_test: ", X_test.shape)
print("Ukuran y_train: ", y_train.shape)
print("Ukuran y_test: ", y_test.shape)

"""###Standarisasi
---
Proses ini digunakan untuk membuat fitur data menjadi bentuk yang lebih mudah diolah oleh algoritma

Proses ini akan menggunakan fungsi standardScaler yang akan mengurangi nilai rata-rata dan kemudian membaginya dengan standar deviasi. Fungsi ini akan menghasilkan nilai rata-rata 0 dan standar deviasi 1
"""

from sklearn.preprocessing import StandardScaler

numerical_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(3)

"""Seperti yang terlihat pada data diatas, setelah melewati proses standarisasi nilai mean menyentuh 0 dan standar deviasi 1, sehingga proses selanjutnya akan menjadi lebih mudah

##**Model development**
---
Proses sistematis dalam membuat model untuk menyelesaikan masalah.

Dalam proyek ini, model yang akan digunakan yaitu:
*   K-Nearest Neighbour
*   Random Forrest
*   Adaptive Boosting
*   Support Vector Machine
*   Decision Tree Regression

Proses pertama adalah dengan menyiapkan dataframe untuk menyimpan model-model diatas
"""

models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting', 'SVM', 'DecisionTree'])

"""Dilanjutkan dengan mengimplementasikan model:

Model K-Nearest Neighbour(KNN)
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=50, p=1, leaf_size=10)
knn.fit(X_train, y_train)

models.loc['train_mse','KNN'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""Model Random Forrest"""

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)
rf.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=rf.predict(X_train), y_true=y_train)

"""Model Adaptive Boosting"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(n_estimators=50,learning_rate=0.01, random_state=42)
boosting.fit(X_train, y_train)

models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""Model Support Vector Machine"""

from sklearn.svm import SVR

svm = SVR(gamma = 'auto', verbose=True)
svm.fit(X_train, y_train)

models.loc['train_mse','SVM'] = mean_squared_error(y_pred=svm.predict(X_train), y_true=y_train)

"""Model Decission Tree Regression"""

from sklearn.tree import DecisionTreeRegressor

dtree = DecisionTreeRegressor(min_samples_leaf = 1, min_samples_split = 2, max_depth = 1, max_features = 4, random_state = 42)
dtree.fit(X_train, y_train)

models.loc['train_mse', 'DecisionTree'] = mean_squared_error(y_true=y_train, y_pred=dtree.predict(X_train))

"""##**Evaluasi model**
---
Proses untuk mengevaluasi hasil prediksi dari model yang telah dibuat.

Metrik yang digunakan dalam proses evaluasi ini adalah *Mean Squared Error* (MSE). Metrik ini akan dikalikan dengan selisih kuadrat rata-rata nilai sebenarnya dengan hasil prediksi dari model. Namun sebelum melakukan evaluasi, perlu dilakukan scaling pada fitur numerik dalam data uji seperti halnya yang telah dilakukan pada data latih sebelumnya. Hal ini dilakukan agar skala nilai antar keduanya serupa.
"""

# Melakukan scaling pada fitur numerik dalam data uji
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# Melakukan evaluasi pada setiap model yang telah dibuat
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'RandomForest', 'Boosting', 'SVM', 'DecisionTree'])

model_dict = {'KNN': knn, 'RandomForest': rf, 'Boosting': boosting, 'SVM': svm, 'DecisionTree': dtree}

for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

mse

"""Visualisasikan metrik ke dalam bar chart"""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Lakukan pengujian pada setiap model"""

prediksi = X_test.iloc[:3].copy()
pred_dict = {'y_true':y_test[:3]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Berdasarkan dari data diatas yang memperlihatkan berbagai macam nilai hasil prediksi dari setiap model, setiap model menghasilkan nilai prediksi yang bervariatif namun selisihnya tidak terlalu jauh. Nilai prediksi yang selisihnya lumayan jauh dari setiap model dan nilai aktual dihasilkan oleh model Decission Tree Regressor. Sedangkan hasil prediksi yang nilainya mendekati nilai aktual diperoleh oleh model Random Forest.



"""