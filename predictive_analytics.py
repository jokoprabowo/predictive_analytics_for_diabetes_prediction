# -*- coding: utf-8 -*-
"""Predictive_analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VXtCr0p_yoCYAHKIsQ37jzovHldnzZPR

# **Predictive Analytics**

Nama: Joko prabowo <br>
ID: jprabowo <br>
Email: jokoprabowo4550@gmail.com <br>

## **Data loading**
---
Proses dalam menyimpan dan memuat data untuk diproses lebih lanjut
"""

import pandas as pd

url = 'https://github.com/jokoprabowo/predictive_analytics_for_water_quallity_prediction/releases/download/dataset/diabetes.csv'
df = pd.read_csv(url)
df

"""## **Exploratory data analysis**
---
 Proses untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data.

### Deskripsi variabel
---
Proses untuk mendeskripsikan setiap variabel agar variabel tersebut dapat dimengerti secara umum

Berdasarkan informasi dari kaggle, variable-variable diatas dapat diartikan:

Variabel|Keterangan
---|---
Pregnancies|Jumlah kehamilan
Glucose|Kadar glukosa dalam darah
BloodPressure|Tekanan darah
SkinThickness|Ketebalan kulit
Insulin|Kadar insulin dalam tubuh
BMI|Index massa tubuh
DiabetesPedigreeFunction|Presentase diabetes
Age|Umur
Outcome|Nilai akhir (positif = 1) dan (negatif = 0)
"""

df.info()

"""Dari hasil diatas dapat dilihat bahwa:
*   Terdapat 6 data numerik dengan tipe data int64, yaitu: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, dan Age
*   Terdapat 2 data numerik dengan tipe data float64, yaitu: BMI, dan DiabetesPedigreeFunction
*   Terdapat 1 data kategorik dengan tipe data int64, yaitu: Outcome yang merupakan target fitur dari proyek ini.


"""

df.describe()

"""Data diatas memperlihatkan informasi statistik pada setiap kolom yaitu:

Variabel|Keterangan
---|---
count|jumlah sampel
mean|nilai rata-rata
std|standar deviasi
min|nilai minimum
25%|kuartil pertama
50%|kuartil kedua
75%|kuartil ketiga
max|nilai maximum

### Unvariate analysis
---
Proses untuk menganalisis data terhadap satu variabel secara mandiri
"""

df.info()

"""Bagi fitur menjadi numerical dan categorical features berdasarkan data diatas, dan lakukan proses analisis pada setiap fiturnya"""

numerical_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
categorical_features = ['Outcome']

# Fitur outcome
feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df_outcome = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_outcome)
count.plot(kind='bar', title='Plot penderita diabetes');

"""Berdasarkan gambar diatas, dapat disimpulkan bahwa mayoritas responden bukan merupakan penderita diabetes (Outcome = 0)"""

import matplotlib.pyplot as plt
import seaborn as sns

df.hist(bins=50, figsize=(20,15))
plt.show()

"""Berdasarkan histogram diatas dapat disimpulkan bahwa:
*   Plot histogram SkinThickness dan Insulin tidak berdistribusi normal
*   Plot histogram dari Glucose, BloodPressure, dan BMI cukup berdistribusi normal
*   Plot histogram dari Pregnancies, DiabetesPedigreeFunction, dan Age berdistribusi cenderung miring ke kanan sehingga mayoritas data memiliki nilai dibawah rata-rata

### Multivariate analysis
---
Proses yang digunakan untuk menganalisis hubungan antara dua variabel atau lebih

Untuk menganalisis hubungan antara fitur target (Outcome) dengan fitur lainnya pada proyek ini, fungsi stripplot() akan digunakan sebagai visualisasi hubungannya
"""

df_features = df.columns.tolist()
df_features.remove('Outcome')

# Membuat plot strip perbandingan untuk setiap fitur
for column in df_features:
  plt.figure(figsize = (8, 6))
  sns.stripplot(data = df, x = "Outcome", y = column)
  plt.title(f'Plot strip kemungkinan diabetes terhadap {column}')
  plt.xlabel('Outcome')
  plt.ylabel(f'{column}')
  plt.show()

"""Berdasarkan visualisasi dari gambar-gambar diatas dapat disimpulkan bahwa:
*   Tidak terdapat perbedaan yang mencolok antara fitur-fitur diatas dengan kemungkinan menderita diabetes
*   Namun, dalam rentang kandungan glukosa di dalam tubuh orang pengidap diabetes berkisar 80 - 200 mg/dL namun berkisar 40 - 180 mg/dL untuk yang bukan pengidap diabetes




"""

plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_features].corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Dari heatmap diatas dapat terlihat bahwa:
*   Umur punya korelasi yang cukup tinggi terhadap jumlah kehamilan, layaknya kadar insulin dalam tubuh terhadap ketebalan kulit
*   Namun Umur punya korelasi yang sangat rendah terhadap kadar insulin dalam tubuh, layaknya jumlah kehamilan terhadap ketebalan kulit

## **Data preparation**
---
Proses untuk menyiapkan data mentah agar dapat diproses dan dianalisis lebih lanjut.

### Menangani missing value dan outliners
---
Proses untuk menghapus kolom yang bernilai kosong (NaN) serta terduplikat, untuk mengatasi data ganda dan data yang tidak lengkap
"""

# menampilkan total data kosong
df.isna().sum()

"""Berdasarkan hasil diatas, tidak ada data kosong dalam dataset ini

Kemudian lakukan cek terhadap data terduplikasi
"""

df.duplicated().sum()

"""Keterangan diatas menyatakan bahwa tidak ada data yang terduplikasi"""

df_features = df.columns.tolist()
df_features.remove('Outcome')

for column in df_features:
  plt.figure(figsize=(8,2))
  sns.boxplot(x=df[column])
  plt.title(f'Boxplot of {column}')
  plt.show()

"""Gambar diatas merupakan visualisasi data untuk mendeteksi outliners pada setiap fitur numerik, kemudian outliners tersebut akan diatasi menggunakan metode IQR"""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

df_out = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]
df.shape, df_out.shape

"""Hasil diatas merupakan total data sebelum dan sesudah menangani data outliner

###Train-Test-Split
---
Proses ini dilakukan untuk membagi data menjadi data latih(train), dan data uji(test) yang digunakan untuk membuat model

Sebelum membuat data training dan test, data perlu dipisahkan antara fitur komposisi dan fitur target
"""

from sklearn.model_selection import train_test_split

X = df_out[df_features]
y = df_out['Outcome']

# Komposisi data train dan data test adalah 80% dan 20%
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

print("Ukuran X_train: ", X_train.shape)
print("Ukuran X_test: ", X_test.shape)
print("Ukuran y_train: ", y_train.shape)
print("Ukuran y_test: ", y_test.shape)

"""###Standarisasi
---
Proses ini digunakan untuk membuat fitur data menjadi bentuk yang lebih mudah diolah oleh algoritma

Proses ini akan menggunakan fungsi standardScaler yang akan mengurangi nilai rata-rata dan kemudian membaginya dengan standar deviasi. Fungsi ini akan menghasilkan nilai rata-rata 0 dan standar deviasi 1
"""

from sklearn.preprocessing import StandardScaler

numerical_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(3)

"""Seperti yang terlihat pada data diatas, setelah melewati proses standarisasi nilai mean menyentuh 0 dan standar deviasi 1, sehingga proses selanjutnya akan menjadi lebih mudah

## **Model development**
---
Proses sistematis dalam membuat model untuk menyelesaikan masalah.

Dalam proyek ini, model yang akan digunakan yaitu:
*   K-Nearest Neighbour
*   Random Forest
*   Adaptive Boosting
*   Support Vector Machine
*   Decision Tree

Implementasikan model:

---
<br>
Model K-Nearest Neighbour(KNN)
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

knn = KNeighborsClassifier(n_neighbors=25, p=2, leaf_size=10)
knn.fit(X_train, y_train)

"""Parameter yang digunakan dalam model KNN diantaranya:
*   n_neighbors = 25 (Jumlah tetangga)
*   p = 2 (Kekuatan parameter untuk metrik minkowski, pada model ini digunakan minkowski_distance (l_p))
*   leaf_size = 10 (Ukuran daun yang akan diteruskan ke BallTree atau KDTree)
---

Model Random Forrest
"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=200, max_depth=8, random_state=42)
rf.fit(X_train, y_train)

"""Parameter yang digunakan dalm model Random Forest diantaranya:
*   n_estimators = 200 (Jumlah pohon di dalam hutan)
*   max_depth = 8 (Total kedalaman pohon)
*   random_state = 42 (Jumlah sampel acak)
---

Model Adaptive Boosting
"""

from sklearn.ensemble import AdaBoostClassifier

boosting = AdaBoostClassifier(n_estimators=100,learning_rate=0.1, random_state=42)
boosting.fit(X_train, y_train)

"""Parameter yang digunakan dalm model Random Forest diantaranya:
*   n_estimators = 100 (Jumlah penaksir dimana peningkatan dihentikan)
*   learning_rate = 0.1 (Kecepatan pembelajaran)
*   random_state = 42 (Jumlah sampel acak)
---

Model Support Vector Machine
"""

from sklearn.svm import SVC

svm = SVC(gamma = 'scale', C=10, kernel='linear')
svm.fit(X_train, y_train)

"""Parameter yang digunakan dalm model Random Forest diantaranya:
*   gamma = scale (koefisien kernel yang digunakan = 1/jumlah fitur)
*   C = 10 (Parameter regularisasi)
*   kernel= linear (Menentukan tipe kernel yang akan digunakan dalam algoritma)
---

Model Decission Tree
"""

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_depth = 1, max_features = 4, random_state = 42)
dtree.fit(X_train, y_train)

"""Parameter yang digunakan dalm model Random Forest diantaranya:
*   min_sample_leaf = 10 (Jumlah minimum sampel yang diperlukan untuk berada pada simpul daun)
*   min_samples_split = 2 (Jumlah minimum sampel yang diperlukan untuk memisahkan node internal)
*   max_depth = 8 (Kedalaman maksimum dari pohon)
*   max_features = 1 (Jumlah fitur yang perlu dipertimbangkan saat mencari pemisahan terbaik)
*   random_state = 42 (Jumlah sampel acak)
---

## **Evaluasi model**
---
Proses untuk mengevaluasi hasil prediksi dari model yang telah dibuat.

Metrik yang digunakan dalam proses evaluasi ini yaitu:
*   Akurasi (Accuracy) merupakan proporsi data yang berhasil diprediksi dengan benar dari seluruh data yang diprediksi.
*   Presisi (Precision) merupakan proporsi data positif yang berhasil diprediksi dengan benar dari seluruh data yang diprediksi positif.
*   Sensitivitas (Recall) merupakan proporsi data positif yang berhasil diprediksi dengan benar dari seluruh data yang aslinya positif.
*   skor f1 (F1 Score) merupakan rata-rata harmonik dari precision dan recall untuk mendapatkan sebuah metrik yang seimbang.


<br>
 Namun sebelum melakukan evaluasi, perlu dilakukan scaling pada fitur numerik dalam data uji seperti halnya yang telah dilakukan pada data latih sebelumnya. Hal ini dilakukan agar skala nilai antar keduanya serupa.
"""

# Melakukan scaling pada fitur numerik dalam data uji
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

# Melakukan evaluasi pada setiap model yang telah dibuat
models = pd.DataFrame(index=['KNN', 'RandomForest', 'Boosting', 'SVM', 'DecisionTree'],
                      columns=['Accuracy', 'Precision', 'Recall', 'F1-score', 'Support'])

model_dict = {'KNN': knn, 'RandomForest': rf, 'Boosting': boosting, 'SVM': svm, 'DecisionTree': dtree}

for name, model in model_dict.items():
    models.loc[name, 'Accuracy'] = accuracy_score(y_true=y_test, y_pred=model.predict(X_test))
    models.loc[name, 'Precision'] = precision_score(y_true=y_test, y_pred=model.predict(X_test))
    models.loc[name, 'Recall'] = recall_score(y_true=y_test, y_pred=model.predict(X_test))
    models.loc[name, 'F1-score'] = f1_score(y_true=y_test, y_pred=model.predict(X_test))
    models.loc[name, 'Support'] = y_test.shape[0]

models

"""Visualisasikan akurasi ke dalam bar chart"""

plt.figure(figsize = (8, 6))
barplot = sns.barplot(data = models, x = models.index, y = 'Accuracy')

for index, value in enumerate(models['Accuracy']):
    barplot.text(index, value + 0.01, f"{value:.4f}", color = 'black', ha = 'center')

plt.title('Perbandingan akurasi')
plt.xlabel('Model')
plt.ylabel('Akurasi')
plt.show()

"""Berdasarkan tabel dan gambar diatas, setiap model menghasilkan skor metrik yang bervariasi. Namun jika diperhatikan lebih detail, hasil skor metrik dari setiap model tidak terpaut terlalu jauh. Dan dari gambar di atas dapat diambil kesimpulan bahwa model yang menghasilkan skor akurasi terendah adalah model Decision Tree dengan akurasi 71.88% dan skor akurasi tertinggi adalah model Adaptive Boosting dengan akurasi 84.38%"""